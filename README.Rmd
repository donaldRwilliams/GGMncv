---
output: github_document
bibliography: man/bib/REFERENCES.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

<img src="man/figures/hex.png" width = 250 />

# GGMncv: Gaussian Graphical Models with Non-convex Penalties

[![Build Status](https://travis-ci.org/donaldRwilliams/GGMncv.svg?branch=master)](https://travis-ci.org/donaldRwilliams/GGMncv)

The goal of GGMncv is to provide non-convex penalties for estimating Gaussian graphical models. These are known 
to overcome the various limitations of lasso, including (but not limited to) inconsistent model selection, biased estimates, and a high false positive rate.

## Installation

You can install the released version of GGMncv from
[CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("GGMncv")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("donaldRwilliams/GGMncv")
```


## Penalties
The following are implemented in `GGMncv`:

1. Atan [`penalty = "atan"`; @wang2016variable]. This is currently the default.

2. Seamless L0  [`penalty = "selo"`; @dicker2013variable]

3. Exponential [`penalty = "exp"`; @wang2018variable]

4. Smoothly clipped absolute deviation [`penalty = scad`; @fan2001variable]

5. Minimax concave penalty `penalty = mcp`; @zhang2010nearly]

Note that options 1-3 are continuous approximations to the L0 penalty, that is, best subsets model selection. However, the solution is computationally efficient and solved with the local linear approximation described in @fan2009network or the one-step approach described in @zou2008one.

## Tuning Parameter
The methods in **GGMncv** are currently tuning free. This is accomplished by setting the tuning parameter to `sqrt(log(p)/n)` [see for example @zhang2018silggm; @li2015flare; @jankova2015confidence].


## Example
A GGM can be fitted as follows

```r
library(GGMncv)

# data
Y <- GGMncv::ptsd[,1:10]

# polychoric
S <- psych::polychoric(Y)$rho

# fit model
fit <- GGMncv(S, n = nrow(Y), 
              penalty = "atan", 
              LLA = TRUE)

# print
fit

#>       1     2     3     4     5     6     7     8     9    10
#> 1  0.000 0.255 0.000 0.309 0.101 0.000 0.000 0.000 0.073 0.000
#> 2  0.255 0.000 0.485 0.000 0.000 0.000 0.122 0.000 0.000 0.000
#> 3  0.000 0.485 0.000 0.185 0.232 0.000 0.000 0.000 0.000 0.000
#> 4  0.309 0.000 0.185 0.000 0.300 0.000 0.097 0.000 0.000 0.243
#> 5  0.101 0.000 0.232 0.300 0.000 0.211 0.166 0.000 0.000 0.000
#> 6  0.000 0.000 0.000 0.000 0.211 0.000 0.234 0.079 0.000 0.000
#> 7  0.000 0.122 0.000 0.097 0.166 0.234 0.000 0.000 0.000 0.000
#> 8  0.000 0.000 0.000 0.000 0.000 0.079 0.000 0.000 0.000 0.114
#> 9  0.073 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.261
#> 10 0.000 0.000 0.000 0.243 0.000 0.000 0.000 0.114 0.261 0.000
```


## Bootstrapping
It might be tempting to perform a bootstrap and then attempt to construct confidence intervals for the edges. However, in general, these "confidence" intervals do not have the correct properties to be considered
a confidence intervals (see  [Wikipedia](https://en.wikipedia.org/wiki/Confidence_interval)). This 
sentiment is echoed in Section 3.1, "Why standard bootstrapping and subsampling do not work As," of 
@Buhlmann2014:

> The (limiting) distribution of such a sparse estimator is non-Gaussian with 
> point mass at zero, and this is the reason why standard bootstrap or subsampling 
> techniques do not provide valid confidence regions or p-values (pp. 7-8).


For this reason, it is common to not provide the standard errors for penalized models. **GGMncv** follows the idea of behind the **penalized** `R` package:


>It is a very natural question to ask for standard errors of regression coefficients
>or other estimated quantities. In principle such standard errors can easily be
>calculated, e.g. using the bootstrap. Still, this package deliberately does not provide them. The reason for this is that standard errors are not very meaningful for strongly biased estimates
such as arise from penalized estimation methods [p.18, @goeman2018l1]

Thus, at this time, confidence intervals are not provided for the partial correlations. However, **GGMncv** 
does included the so-called variable inclusion "probability" for each relation [see p 1523 in @bunea2011penalized; 
and Figure 6.7 in @hastie2015statistical]. These are computed using a non-parametric bootstrap strategy.

### Variable Inclusion "Probability"

```r
# data
Y <- GGMncv::ptsd[,1:10]

# polychoric
S <- psych::polychoric(Y)$rho

# fit model
fit <- GGMncv(S, n = nrow(Y), 
              penalty = "atan", 
              vip = TRUE)

# plot
plot(fit, size = 4)
```
![](man/figures/vip.png)

## References
