---
output: github_document
bibliography: man/bib/REFERENCES.bib
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

<img src="man/figures/hex.png" width = 250 />

# GGMncv

[![Build Status](https://travis-ci.org/donaldRwilliams/GGMncv.svg?branch=master)](https://travis-ci.org/donaldRwilliams/GGMncv)

The goal of GGMncv is to provide non-convex penalties for estimating Gaussian graphical models. These are known 
to overcome the various limitations of lasso, including (but not limited to) consistent model selection, nearly unbiased estimates, and a lower false positive rate.

## Installation

You can install the released version of GGMncv from
[CRAN](https://CRAN.R-project.org) with:

``` r
install.packages("GGMncv")
```

And the development version from [GitHub](https://github.com/) with:

``` r
# install.packages("devtools")
devtools::install_github("donaldRwilliams/GGMncv")
```


## Penalties
The following are implemented in `GGMncv`:

1. Atan [`penalty = "atan"`; @wang2016variable]. This is currently the default.

2. Seamless L0  [`penalty = "selo"`; @dicker2013variable]

3. Exponential [`penalty = "exp"`; @wang2018variable]

4. Smoothly clipped absolute deviation [`penalty = scad`; @fan2001variable]

5. Minimax concave penalty `penalty = mcp`; @zhang2010nearly]

Note that options 1-3 are continuous approximations to the L0 penalty, that is, best subsets model selection. However, the solution is computationally efficient and solved with the local linear approximation described in @fan2009network or the one-step approach described in @zou2008one.

## Tuning Parameter
`GGMncv` is currently tuning free. This is accomplished by setting the tuning parameter to `sqrt(log(p)/n)` 
[see for example @zhang2018silggm; @li2015flare; @jankova2015confidence].


## Example
